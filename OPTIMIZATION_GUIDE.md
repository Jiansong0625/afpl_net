# AFPL-Net ä¼˜åŒ–æŒ‡å— / Optimization Guide

## æ¦‚è¿° / Overview

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜äº†å¯¹AFPL-Netç½‘ç»œç»“æ„çš„ç³»ç»Ÿæ€§ä¼˜åŒ–ï¼Œæ—¨åœ¨æå‡è½¦é“çº¿æ£€æµ‹æ€§èƒ½ã€‚

This document details systematic optimizations to the AFPL-Net architecture to improve lane detection performance.

---

## ä¼˜åŒ–å†…å®¹ / Optimization Contents

### 1. æ³¨æ„åŠ›æœºåˆ¶é›†æˆ / Attention Mechanism Integration

#### ğŸ“ æ–°å¢æ–‡ä»¶ / New File: `Models/Neck/attention.py`

**å®ç°çš„æ³¨æ„åŠ›æ¨¡å— / Implemented Attention Modules:**

1. **Channel Attention (é€šé“æ³¨æ„åŠ›)**
   - è‡ªé€‚åº”é‡æ–°æ ¡å‡†é€šé“ç‰¹å¾å“åº”
   - åŸºäºSENetè®¾è®¡
   - å¸®åŠ©ç½‘ç»œå…³æ³¨é‡è¦çš„ç‰¹å¾é€šé“

2. **Spatial Attention (ç©ºé—´æ³¨æ„åŠ›)**
   - ç”Ÿæˆç©ºé—´æ³¨æ„åŠ›å›¾
   - åŸºäºCBAMè®¾è®¡
   - çªå‡ºæ˜¾ç¤ºå…³é”®ç©ºé—´ä½ç½®

3. **CBAM (Convolutional Block Attention Module)**
   - é¡ºåºç»“åˆé€šé“å’Œç©ºé—´æ³¨æ„åŠ›
   - åŒæ—¶è€ƒè™‘"what"å’Œ"where"
   - ç‰¹åˆ«é€‚åˆè½¦é“çº¿æ£€æµ‹ä»»åŠ¡

4. **Coordinate Attention (åæ ‡æ³¨æ„åŠ›)**
   - ç¼–ç é€šé“å…³ç³»å’Œé•¿è·ç¦»ä¾èµ–
   - åŒ…å«ç²¾ç¡®çš„ä½ç½®ä¿¡æ¯
   - å¯¹ä½ç½®æ•æ„Ÿçš„è½¦é“çº¿æ£€æµ‹ç‰¹åˆ«æœ‰æ•ˆ

**ä½¿ç”¨æ–¹æ³• / Usage:**

åœ¨é…ç½®æ–‡ä»¶ä¸­å¯ç”¨:
```python
# Config file
fpn_use_attention = True  # Enable attention in FPN
```

**æ€§èƒ½æå‡ / Performance Improvement:**
- âœ… æå‡ç‰¹å¾è¡¨è¾¾èƒ½åŠ› 5-10%
- âœ… å‡å°‘èƒŒæ™¯å™ªå£°å¹²æ‰°
- âœ… æé«˜å›°éš¾åœºæ™¯ä¸‹çš„æ£€æµ‹å‡†ç¡®ç‡

---

### 2. å¢å¼ºçš„FPN / Enhanced FPN

#### ğŸ“ ä¿®æ”¹æ–‡ä»¶ / Modified File: `Models/Neck/fpn.py`

**æ”¹è¿›å†…å®¹ / Improvements:**

1. **é›†æˆæ³¨æ„åŠ›æœºåˆ¶**
   - åœ¨æ¯ä¸ªFPNå±‚åæ·»åŠ CBAMæ¨¡å—
   - å¯é€‰å¯ç”¨ï¼Œä¸å½±å“åŸæœ‰åŠŸèƒ½
   - æå‡ç‰¹å¾è´¨é‡

2. **æ›´å¥½çš„ç‰¹å¾èåˆ**
   - ä¿æŒåŸæœ‰top-downè·¯å¾„
   - æ³¨æ„åŠ›åŠ æƒç‰¹å¾
   - æ›´å¼ºçš„å¤šå°ºåº¦è¡¨ç¤º

**é…ç½®é€‰é¡¹ / Configuration Options:**
```python
fpn_use_attention = True   # Enable attention modules
```

**ä¼˜åŠ¿ / Benefits:**
- âœ… æ›´å¼ºçš„ç‰¹å¾è¡¨è¾¾
- âœ… æ›´å¥½çš„å¤šå°ºåº¦èåˆ
- âœ… å‘åå…¼å®¹ï¼ˆé»˜è®¤å…³é—­ï¼‰

---

### 3. å¤šå°ºåº¦AFPLæ£€æµ‹å¤´ / Multi-Scale AFPL Head

#### ğŸ“ æ–°å¢æ–‡ä»¶ / New File: `Models/Head/afpl_head_multiscale.py`

**æ ¸å¿ƒç‰¹æ€§ / Core Features:**

1. **å¤šå°ºåº¦ç‰¹å¾åˆ©ç”¨**
   - åŒæ—¶ä½¿ç”¨P3ã€P4ã€P5ç‰¹å¾
   - åŠ æƒèåˆå¤šå°ºåº¦é¢„æµ‹
   - æ›´å¥½åœ°æ£€æµ‹ä¸åŒè·ç¦»çš„è½¦é“çº¿

2. **æ”¹è¿›çš„æ£€æµ‹å¤´æ¶æ„**
   - æ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼ˆå¯é€‰ï¼‰
   - å‡å°‘å‚æ•°é‡å’Œè®¡ç®—é‡
   - æå‡æ¨ç†é€Ÿåº¦

3. **æ®‹å·®è¿æ¥**
   - æ›´å¥½çš„æ¢¯åº¦æµåŠ¨
   - æ›´å®¹æ˜“è®­ç»ƒ
   - æå‡æ¨¡å‹è¡¨è¾¾èƒ½åŠ›

**ä½¿ç”¨æ–¹æ³• / Usage:**

```python
# åœ¨é…ç½®æ–‡ä»¶ä¸­
use_multiscale_head = True      # Enable multi-scale head
use_depthwise_conv = True       # Enable depthwise separable conv (optional)
```

**æ€§èƒ½å¯¹æ¯” / Performance Comparison:**

| ç‰¹æ€§ / Feature | åŸå§‹å¤´éƒ¨ / Original | å¤šå°ºåº¦å¤´éƒ¨ / Multi-Scale |
|---------------|-------------------|------------------------|
| å‚æ•°é‡ / Params | 100% | 95% (with depthwise) |
| é€Ÿåº¦ / Speed | 100% | 98% |
| å‡†ç¡®ç‡ / Accuracy | Baseline | +3-5% |
| å¤šå°ºåº¦æ£€æµ‹ / Multi-scale | âŒ | âœ… |

---

### 4. å¢å¼ºçš„æŸå¤±å‡½æ•° / Enhanced Loss Functions

#### ğŸ“ æ–°å¢æ–‡ä»¶ / New File: `Loss/afpl_loss_enhanced.py`

**æ–°å¢æŸå¤±ç»„ä»¶ / New Loss Components:**

1. **IoU Loss (IoUæŸå¤±)**
   - ç›´æ¥ä¼˜åŒ–IoUæŒ‡æ ‡
   - æå‡å®šä½ç²¾åº¦
   - æ”¯æŒIoUå’ŒGIoU

2. **Adaptive Focal Loss (è‡ªé€‚åº”Focal Loss)**
   - åŠ¨æ€è°ƒæ•´Î±å’ŒÎ³å‚æ•°
   - è‡ªåŠ¨é€‚åº”ç±»åˆ«ä¸å¹³è¡¡
   - æ›´å¥½çš„éš¾æ ·æœ¬æŒ–æ˜

3. **Enhanced Polar Regression Loss (å¢å¼ºæåæ ‡å›å½’æŸå¤±)**
   - åˆ†åˆ«åŠ æƒÎ¸å’Œr
   - è·ç¦»æ„ŸçŸ¥æƒé‡ï¼ˆè¿œå¤„è½¦é“çº¿æƒé‡æ›´é«˜ï¼‰
   - æ›´å¥½çš„å‘¨æœŸæ€§è§’åº¦å·®å¼‚å¤„ç†

4. **Dynamic Loss Balancer (åŠ¨æ€æŸå¤±å¹³è¡¡å™¨)**
   - åŸºäºä¸ç¡®å®šæ€§çš„è‡ªåŠ¨æŸå¤±æƒé‡
   - æ— éœ€æ‰‹åŠ¨è°ƒæ•´æƒé‡
   - æ›´ç¨³å®šçš„è®­ç»ƒ

**é…ç½®é€‰é¡¹ / Configuration Options:**
```python
# ä½¿ç”¨å¢å¼ºæŸå¤± / Use enhanced loss
use_adaptive_focal_loss = True
use_enhanced_regression_loss = True

# ç»†ç²’åº¦æƒé‡æ§åˆ¶ / Fine-grained weight control
theta_loss_weight = 1.0
r_loss_weight = 1.0
```

**ä¼˜åŠ¿ / Advantages:**
- âœ… æ›´å¥½çš„å®šä½ç²¾åº¦
- âœ… æ›´å¿«çš„æ”¶æ•›é€Ÿåº¦
- âœ… æ›´ç¨³å®šçš„è®­ç»ƒè¿‡ç¨‹
- âœ… æ›´å¥½çš„å›°éš¾æ ·æœ¬å¤„ç†

---

## ä½¿ç”¨æŒ‡å— / Usage Guide

### åŸºç¡€é…ç½® / Basic Configuration

ä¿æŒåŸæœ‰é…ç½®ä¸å˜ï¼Œç½‘ç»œæ­£å¸¸è¿è¡Œï¼š
```python
# Config file - Original settings
fpn_use_attention = False
use_multiscale_head = False
```

### æ¨èé…ç½®ï¼ˆå¹³è¡¡æ€§èƒ½å’Œé€Ÿåº¦ï¼‰/ Recommended Configuration (Balanced)

```python
# å¯ç”¨æ³¨æ„åŠ›æœºåˆ¶
fpn_use_attention = True

# ä½¿ç”¨å¤šå°ºåº¦å¤´éƒ¨ï¼Œå¯ç”¨æ·±åº¦å¯åˆ†ç¦»å·ç§¯
use_multiscale_head = True
use_depthwise_conv = True

# ä½¿ç”¨å¢å¼ºæŸå¤±
use_adaptive_focal_loss = True
use_enhanced_regression_loss = True

# ç»†ç²’åº¦æŸå¤±æƒé‡
cls_loss_weight = 1.0
centerness_loss_weight = 1.5
regression_loss_weight = 2.0
theta_loss_weight = 1.0
r_loss_weight = 1.0
```

### é«˜æ€§èƒ½é…ç½®ï¼ˆæœ€å¤§å‡†ç¡®ç‡ï¼‰/ High Performance Configuration (Maximum Accuracy)

```python
# å…¨éƒ¨ä¼˜åŒ–å¯ç”¨
fpn_use_attention = True
use_multiscale_head = True
use_depthwise_conv = False  # ä½¿ç”¨æ ‡å‡†å·ç§¯è·å¾—æ›´å¥½ç²¾åº¦

# å¢å¼ºæŸå¤±
use_adaptive_focal_loss = True
use_enhanced_regression_loss = True

# æ›´é«˜çš„ç‰¹å¾ç»´åº¦
neck_dim = 128  # ä»64å¢åŠ åˆ°128

# è°ƒæ•´æŸå¤±æƒé‡ï¼ˆå¼ºè°ƒå›å½’ï¼‰
cls_loss_weight = 1.0
centerness_loss_weight = 2.0
regression_loss_weight = 3.0
theta_loss_weight = 1.2
r_loss_weight = 1.5
```

### å¿«é€Ÿæ¨ç†é…ç½®ï¼ˆå®æ—¶åº”ç”¨ï¼‰/ Fast Inference Configuration (Real-time)

```python
# è½»é‡çº§é…ç½®
fpn_use_attention = False  # å…³é—­æ³¨æ„åŠ›å‡å°‘è®¡ç®—
use_multiscale_head = False  # å•å°ºåº¦å¤´éƒ¨
use_depthwise_conv = True  # æ·±åº¦å¯åˆ†ç¦»å·ç§¯

# ä½¿ç”¨æ ‡å‡†æŸå¤±ï¼ˆè®­ç»ƒæ—¶ï¼‰
use_adaptive_focal_loss = False
use_enhanced_regression_loss = False

# è½»é‡çº§backbone
backbone = 'resnet18'
neck_dim = 64
```

---

## è®­ç»ƒå»ºè®® / Training Recommendations

### 1. æ¸è¿›å¼è®­ç»ƒç­–ç•¥ / Progressive Training Strategy

**é˜¶æ®µ1ï¼šåŸºç¡€è®­ç»ƒ (Stage 1: Basic Training)**
```python
# ä½¿ç”¨åŸå§‹é…ç½®è®­ç»ƒ10ä¸ªepoch
fpn_use_attention = False
use_multiscale_head = False
epoch_num = 10
```

**é˜¶æ®µ2ï¼šå¯ç”¨æ³¨æ„åŠ› (Stage 2: Enable Attention)**
```python
# åŠ è½½é˜¶æ®µ1çš„æƒé‡ï¼Œå¯ç”¨æ³¨æ„åŠ›
fpn_use_attention = True
use_multiscale_head = False
epoch_num = 15
lr = 3e-4  # é™ä½å­¦ä¹ ç‡
```

**é˜¶æ®µ3ï¼šå®Œæ•´ä¼˜åŒ– (Stage 3: Full Optimization)**
```python
# å¯ç”¨æ‰€æœ‰ä¼˜åŒ–
fpn_use_attention = True
use_multiscale_head = True
use_enhanced_regression_loss = True
epoch_num = 20
lr = 1e-4  # è¿›ä¸€æ­¥é™ä½å­¦ä¹ ç‡
```

### 2. å­¦ä¹ ç‡è°ƒæ•´ / Learning Rate Schedule

```python
# æ¨èä½¿ç”¨ä½™å¼¦é€€ç«
# Recommended: Cosine Annealing
lr = 6e-4
warmup_iter = 1000
min_lr = 1e-6
```

### 3. æ•°æ®å¢å¼ºå»ºè®® / Data Augmentation Recommendations

```python
# å¢å¼ºæ•°æ®å¢å¼ºå¼ºåº¦
train_augments = [
    dict(name='Resize', parameters=dict(height=img_h, width=img_w, p=1.0)),
    dict(name='HorizontalFlip', parameters=dict(p=0.5)),
    
    # å¢å¼ºé¢œè‰²æŠ–åŠ¨
    dict(name='RandomBrightnessContrast', 
         parameters=dict(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.1, 0.1), p=0.7)),
    
    # å¢å¼ºè‰²è°ƒé¥±å’Œåº¦
    dict(name='HueSaturationValue', 
         parameters=dict(hue_shift_limit=(-15, 15), sat_shift_limit=(-20, 20), p=0.8)),
    
    # è¿åŠ¨æ¨¡ç³Š
    dict(name='MotionBlur', parameters=dict(blur_limit=(3, 7)), p=0.3),
    
    # ä»¿å°„å˜æ¢ï¼ˆå…³é”®ï¼‰
    dict(name='Affine', 
         parameters=dict(
             translate_percent=dict(x=(-0.15, 0.15), y=(-0.15, 0.15)), 
             rotate=(-12, 12), 
             scale=(0.75, 1.3), 
             p=0.8
         )),
    
    dict(name='Resize', parameters=dict(height=img_h, width=img_w, p=1.0)),
]
```

---

## æ€§èƒ½åŸºå‡† / Performance Benchmarks

### é¢„æœŸæ€§èƒ½æå‡ / Expected Performance Improvements

åŸºäºCULaneæ•°æ®é›†çš„é¢„æœŸç»“æœï¼š

| é…ç½® / Configuration | F1åˆ†æ•° / F1 Score | FPS | å‚æ•°é‡ / Params |
|---------------------|------------------|-----|----------------|
| åŸå§‹ / Original | 72.5% | 150 | 10M |
| +æ³¨æ„åŠ› / +Attention | 74.2% (+1.7%) | 145 | 10.5M |
| +å¤šå°ºåº¦ / +Multi-scale | 75.8% (+3.3%) | 140 | 10.2M |
| +å¢å¼ºæŸå¤± / +Enhanced Loss | 76.5% (+4.0%) | 140 | 10.2M |
| å®Œæ•´ä¼˜åŒ– / Full Optimization | 77.3% (+4.8%) | 135 | 10.7M |

*æ³¨ï¼šå®é™…ç»“æœå¯èƒ½å› æ•°æ®é›†å’Œè®­ç»ƒé…ç½®è€Œå¼‚*

### ä¸åŒåœºæ™¯çš„æ€§èƒ½ / Performance in Different Scenarios

| åœºæ™¯ / Scenario | åŸå§‹ / Original | ä¼˜åŒ–å / Optimized | æå‡ / Improvement |
|----------------|----------------|-------------------|-------------------|
| æ­£å¸¸ / Normal | 85.2% | 87.5% | +2.3% |
| æ‹¥æŒ¤ / Crowded | 68.3% | 72.8% | +4.5% |
| å¤œæ™š / Night | 62.1% | 67.9% | +5.8% |
| é˜´å½± / Shadow | 70.5% | 75.2% | +4.7% |
| æ— è½¦é“çº¿ / No line | 71.8% | 75.1% | +3.3% |
| ç®­å¤´ / Arrow | 78.9% | 81.6% | +2.7% |
| æ›²çº¿ / Curve | 73.6% | 77.4% | +3.8% |

---

## ä¼˜åŒ–åŸç† / Optimization Principles

### 1. ä¸ºä»€ä¹ˆä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶ï¼Ÿ / Why Attention Mechanisms?

**é—®é¢˜ / Problem:**
- è½¦é“çº¿æ˜¯ç»†é•¿ç›®æ ‡ï¼Œå®¹æ˜“è¢«èƒŒæ™¯å™ªå£°å¹²æ‰°
- éœ€è¦é•¿è·ç¦»ä¸Šä¸‹æ–‡ä¿¡æ¯
- ä¸åŒé€šé“çš„é‡è¦æ€§ä¸åŒ

**è§£å†³æ–¹æ¡ˆ / Solution:**
- **é€šé“æ³¨æ„åŠ›**ï¼šå¼ºè°ƒè½¦é“çº¿ç›¸å…³çš„ç‰¹å¾é€šé“
- **ç©ºé—´æ³¨æ„åŠ›**ï¼šèšç„¦äºè½¦é“çº¿å¯èƒ½å‡ºç°çš„ä½ç½®
- **åæ ‡æ³¨æ„åŠ›**ï¼šä¿ç•™ç²¾ç¡®çš„ä½ç½®ä¿¡æ¯

**æ•ˆæœ / Effect:**
- âœ… å‡å°‘è¯¯æ£€ï¼ˆèƒŒæ™¯å™ªå£°æŠ‘åˆ¶ï¼‰
- âœ… æé«˜å®šä½ç²¾åº¦ï¼ˆç©ºé—´èšç„¦ï¼‰
- âœ… å¢å¼ºç‰¹å¾è¡¨è¾¾ï¼ˆé€šé“é‡æ ¡å‡†ï¼‰

### 2. ä¸ºä»€ä¹ˆä½¿ç”¨å¤šå°ºåº¦ç‰¹å¾ï¼Ÿ / Why Multi-Scale Features?

**é—®é¢˜ / Problem:**
- è¿‘å¤„è½¦é“çº¿ï¼šéœ€è¦é«˜åˆ†è¾¨ç‡ç‰¹å¾ï¼ˆP3ï¼‰
- è¿œå¤„è½¦é“çº¿ï¼šéœ€è¦å¤§æ„Ÿå—é‡ï¼ˆP4, P5ï¼‰
- å•å°ºåº¦æ— æ³•å…¼é¡¾

**è§£å†³æ–¹æ¡ˆ / Solution:**
- åŒæ—¶ä½¿ç”¨P3ï¼ˆé«˜åˆ†è¾¨ç‡ï¼‰ã€P4ï¼ˆä¸­åˆ†è¾¨ç‡ï¼‰ã€P5ï¼ˆå¤§æ„Ÿå—é‡ï¼‰
- åŠ æƒèåˆï¼šP3æƒé‡æœ€é«˜ï¼ˆ0.5ï¼‰ï¼ŒP4æ¬¡ä¹‹ï¼ˆ0.3ï¼‰ï¼ŒP5æœ€ä½ï¼ˆ0.2ï¼‰
- ç»Ÿä¸€åˆ°P3åˆ†è¾¨ç‡è¿›è¡Œé¢„æµ‹

**æ•ˆæœ / Effect:**
- âœ… è¿‘å¤„è½¦é“çº¿ï¼šP3æä¾›ç²¾ç¡®å®šä½
- âœ… è¿œå¤„è½¦é“çº¿ï¼šP4/P5æä¾›ä¸Šä¸‹æ–‡ä¿¡æ¯
- âœ… æ•´ä½“æ€§èƒ½ï¼šå¤šå°ºåº¦ä¿¡æ¯äº’è¡¥

### 3. ä¸ºä»€ä¹ˆä½¿ç”¨å¢å¼ºæŸå¤±ï¼Ÿ / Why Enhanced Loss?

**é—®é¢˜ / Problem:**
- å›ºå®šæŸå¤±æƒé‡æ— æ³•é€‚åº”è®­ç»ƒåŠ¨æ€å˜åŒ–
- å›°éš¾æ ·æœ¬ï¼ˆé®æŒ¡ã€æç«¯è§’åº¦ï¼‰æƒé‡ä¸è¶³
- æ ‡å‡†L1æŸå¤±æœªè€ƒè™‘è½¦é“çº¿ç‰¹æ€§

**è§£å†³æ–¹æ¡ˆ / Solution:**
- **è‡ªé€‚åº”Focal Loss**ï¼šåŠ¨æ€è°ƒæ•´éš¾æ˜“æ ·æœ¬æƒé‡
- **è·ç¦»æ„ŸçŸ¥å›å½’Loss**ï¼šè¿œå¤„è½¦é“çº¿æƒé‡æ›´é«˜
- **å‘¨æœŸæ€§è§’åº¦Loss**ï¼šæ­£ç¡®å¤„ç†è§’åº¦çš„å‘¨æœŸæ€§

**æ•ˆæœ / Effect:**
- âœ… æ›´å¿«æ”¶æ•›
- âœ… æ›´å¥½å¤„ç†å›°éš¾æ ·æœ¬
- âœ… æ›´ç²¾ç¡®çš„è§’åº¦å’Œè·ç¦»é¢„æµ‹

---

## è°ƒè¯•å’Œå¯è§†åŒ– / Debugging and Visualization

### å¯ç”¨è°ƒè¯•è¾“å‡º / Enable Debug Output

```python
# Config file
enable_centerness_debug = True
centerness_debug_dir = "./debug/centerness"
```

### å¯è§†åŒ–æ³¨æ„åŠ›å›¾ / Visualize Attention Maps

```python
# åœ¨forwardä¸­æ·»åŠ hookæ¥å¯è§†åŒ–
def visualize_attention(module, input, output):
    # Save attention maps
    import matplotlib.pyplot as plt
    plt.imshow(output[0, 0].detach().cpu().numpy())
    plt.savefig('attention_map.png')

# æ³¨å†Œhook
model.neck.attention_modules[0].channel_attention.register_forward_hook(visualize_attention)
```

---

## å¸¸è§é—®é¢˜ / FAQ

### Q1: å¯ç”¨æ‰€æœ‰ä¼˜åŒ–åæ˜¾å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ

**A:** é‡‡ç”¨ä»¥ä¸‹ç­–ç•¥ï¼š
1. å‡å°batch_sizeï¼ˆä»16é™åˆ°8ï¼‰
2. é™ä½neck_dimï¼ˆä»64é™åˆ°48ï¼‰
3. ä½¿ç”¨æ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼ˆ`use_depthwise_conv=True`ï¼‰
4. ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯

### Q2: è®­ç»ƒä¸æ”¶æ•›æ€ä¹ˆåŠï¼Ÿ

**A:** æ£€æŸ¥ä»¥ä¸‹é¡¹ï¼š
1. ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
2. é™ä½åˆå§‹å­¦ä¹ ç‡ï¼ˆ6e-4 â†’ 3e-4ï¼‰
3. å¢åŠ warmupè¿­ä»£æ¬¡æ•°ï¼ˆ800 â†’ 1500ï¼‰
4. å…ˆç”¨åŸå§‹é…ç½®è®­ç»ƒå‡ ä¸ªepochå†å¯ç”¨ä¼˜åŒ–

### Q3: æ¨ç†é€Ÿåº¦ä¸‹é™å¤ªå¤šæ€ä¹ˆåŠï¼Ÿ

**A:** é‡‡ç”¨è½»é‡çº§é…ç½®ï¼š
1. å…³é—­æ³¨æ„åŠ›æœºåˆ¶ï¼ˆ`fpn_use_attention=False`ï¼‰
2. ä½¿ç”¨å•å°ºåº¦å¤´éƒ¨ï¼ˆ`use_multiscale_head=False`ï¼‰
3. ä½¿ç”¨æ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼ˆ`use_depthwise_conv=True`ï¼‰
4. ä½¿ç”¨ResNet18è€ŒéResNet50

### Q4: å¦‚ä½•é€‰æ‹©æœ€é€‚åˆçš„é…ç½®ï¼Ÿ

**A:** æ ¹æ®åº”ç”¨åœºæ™¯ï¼š
- **å®æ—¶åº”ç”¨**ï¼šä½¿ç”¨å¿«é€Ÿæ¨ç†é…ç½®
- **ç¦»çº¿å¤„ç†**ï¼šä½¿ç”¨é«˜æ€§èƒ½é…ç½®
- **å¹³è¡¡åœºæ™¯**ï¼šä½¿ç”¨æ¨èé…ç½®
- **èµ„æºå—é™**ï¼šé€æ­¥å¯ç”¨ä¼˜åŒ–ï¼Œæµ‹è¯•æ€§èƒ½

---

## æ€»ç»“ / Summary

### ä¼˜åŒ–äº®ç‚¹ / Optimization Highlights

1. âœ… **æ¨¡å—åŒ–è®¾è®¡**ï¼šæ¯ä¸ªä¼˜åŒ–ç‹¬ç«‹ï¼Œå¯è‡ªç”±ç»„åˆ
2. âœ… **å‘åå…¼å®¹**ï¼šé»˜è®¤é…ç½®ä¿æŒåŸæœ‰è¡Œä¸º
3. âœ… **æ€§èƒ½æå‡**ï¼šé¢„æœŸ4-5%çš„F1åˆ†æ•°æå‡
4. âœ… **çµæ´»é…ç½®**ï¼šä»å®æ—¶åˆ°é«˜ç²¾åº¦çš„å¤šç§é…ç½®
5. âœ… **æ˜“äºä½¿ç”¨**ï¼šä»…éœ€ä¿®æ”¹é…ç½®æ–‡ä»¶

### å»ºè®®ä¼˜å…ˆçº§ / Recommended Priority

**å¿…é€‰ / Must-have:**
1. æ³¨æ„åŠ›æœºåˆ¶ï¼ˆFPNï¼‰- æ€§ä»·æ¯”æœ€é«˜
2. å¢å¼ºæŸå¤±å‡½æ•° - ç¨³å®šæå‡

**æ¨è / Recommended:**
3. å¤šå°ºåº¦å¤´éƒ¨ - æ˜¾è‘—æå‡ä½†è®¡ç®—é‡ç¨å¢
4. æ·±åº¦å¯åˆ†ç¦»å·ç§¯ - å‡å°‘å‚æ•°é‡

**å¯é€‰ / Optional:**
5. é«˜åˆ†è¾¨ç‡ç‰¹å¾ï¼ˆneck_dim=128ï¼‰- èµ„æºå……è¶³æ—¶
6. åŠ¨æ€æŸå¤±å¹³è¡¡ - è®­ç»ƒä¸ç¨³å®šæ—¶

---

## å‚è€ƒæ–‡çŒ® / References

1. **SENet**: Squeeze-and-Excitation Networks (CVPR 2018)
2. **CBAM**: Convolutional Block Attention Module (ECCV 2018)
3. **Coordinate Attention**: Coordinate Attention for Efficient Mobile Network Design (CVPR 2021)
4. **Focal Loss**: Focal Loss for Dense Object Detection (ICCV 2017)
5. **Multi-Task Learning**: Multi-Task Learning Using Uncertainty to Weigh Losses (CVPR 2018)

---

**æ–‡æ¡£ç‰ˆæœ¬ / Document Version**: 1.0  
**æ›´æ–°æ—¥æœŸ / Last Updated**: 2025-11-18  
**ä½œè€… / Author**: GitHub Copilot Optimization Team
