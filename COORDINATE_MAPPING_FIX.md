# Coordinate Mapping Fix

## Problem Statement (Chinese)

ÂùêÊ†áÊ≤°Êò†Â∞ÑÂõûÂéüÂõæÔºöpost_process Âè™ÊòØÊääÁâπÂæÅÂõæÁΩëÊ†ºÂùêÊ†á‰πò strideÔºàÂæóÂà∞ 800√ó320 Á©∫Èó¥ÁöÑÁÇπÔºâÔºåformat_afplnet_output ÂèàÂè™Âú® cfg.img_w/img_h ËåÉÂõ¥ÂÜÖË£ÅÂâ™ (Models/Head/afpl_head.py (lines 284-287), test_afplnet_inference.py (lines 186-205))„ÄÇËØÑ‰º∞Âô®Âç¥ÂÅáËÆæËæìÂÖ•Â∑≤ÁªèÊòØÂéüÂßã 1640√ó590„ÄÅÂπ∂Â∏¶ 270 ÂÉèÁ¥†Ë£ÅÂâ™ÁöÑÂùêÊ†á (Eval/utils/eval_utils.py (lines 65-84))ÔºåÂõ†Ê≠§ÂÜôÂá∫ÁöÑ lane ÂÆûÈôÖË¢´ÂéãÁº©Âà∞ 320 ÂÉèÁ¥†È´ò‰∏îÁº∫Â∞ë cut-height ÂÅèÁßªÔºåËØÑ‰º∞ÁªìÊûúÂøÖÁÑ∂ÂÅèÂ∑Æ„ÄÇÈúÄË¶ÅÂú®ÂÜôÂá∫ÂâçÂØπÁÇπÊâßË°å x *= ori_img_w/img_w, y = y*(ori_img_h-cut_height)/img_h + cut_height„ÄÇ

## Problem Statement (English)

**Coordinates were not mapped back to the original image**: The `post_process` function only multiplies feature map grid coordinates by stride (resulting in points in 800√ó320 space), and `format_afplnet_output` only clips within cfg.img_w/img_h range. However, the evaluator assumes the input coordinates are already in the original 1640√ó590 space with 270-pixel crop offset. This causes lanes to be compressed to 320 pixels in height and missing the cut-height offset, leading to inaccurate evaluation results. The fix requires applying the transformation: `x *= ori_img_w/img_w`, `y = y*(ori_img_h-cut_height)/img_h + cut_height` before writing output.

## Root Cause Analysis

### The Pipeline Flow (Before Fix)

1. **Network Output** (`Models/Head/afpl_head.py` lines 284-287)
   - Feature map coordinates (e.g., 0-100 for a 100√ó40 feature map)
   - Multiplied by `downsample_factor` (stride, typically 8)
   - Results in coordinates in **resized image space** (800√ó320)

2. **format_afplnet_output** (`test_afplnet_inference.py` lines 197-200)
   - Clips coordinates to `[0, img_w) √ó [0, img_h)` = `[0, 800) √ó [0, 320)`
   - Coordinates remain in **resized image space**

3. **write_output_culane_format** (`Eval/utils/eval_utils.py` lines 65-84)
   - Expects coordinates in **original image space**: `[0, 1640) √ó [270, 590)`
   - Samples at y positions from `cut_height` (270) to `ori_img_h` (590)

### The Issue

**Mismatch in coordinate spaces**: The evaluator expects original image coordinates, but receives resized image coordinates, causing:
- Lane x-coordinates compressed by factor of ~0.49 (800/1640)
- Lane y-coordinates compressed by factor of ~0.54 (320/590)
- Missing 270-pixel vertical offset from top crop
- Evaluation metrics incorrectly calculated

## Configuration Values (CULane Dataset)

From `Config/afplnet_culane_r18.py`:

```python
ori_img_h = 590      # Original image height
ori_img_w = 1640     # Original image width
cut_height = 270     # Height cut from top before resize
img_h = 320          # Resized image height
img_w = 800          # Resized image width
```

## Solution Implementation

### Coordinate Mapping Formula

To map from resized image space to original image space:

```python
# X coordinate: simple scaling
x_original = x_resized * (ori_img_w / img_w)
           = x_resized * (1640 / 800)
           = x_resized * 2.05

# Y coordinate: scale and add offset
y_original = y_resized * ((ori_img_h - cut_height) / img_h) + cut_height
           = y_resized * ((590 - 270) / 320) + 270
           = y_resized * 1.0 + 270
```

### Code Changes

**File**: `test_afplnet_inference.py`  
**Function**: `format_afplnet_output`  
**Location**: After line 206 (after filtering points, before sorting)

```python
# Map coordinates from resized image space to original image space
# This is critical for evaluation which expects original image coordinates
if hasattr(cfg, 'ori_img_w') and hasattr(cfg, 'ori_img_h') and hasattr(cfg, 'cut_height'):
    # x: scale from img_w to ori_img_w
    points[:, 0] = points[:, 0] * (cfg.ori_img_w / cfg.img_w)
    # y: scale from img_h to (ori_img_h - cut_height), then add cut_height offset
    points[:, 1] = points[:, 1] * ((cfg.ori_img_h - cfg.cut_height) / cfg.img_h) + cfg.cut_height
```

## Validation

### Unit Test Results

```
Configuration:
  Resized image: 800√ó320
  Original image: 1640√ó590
  Cut height: 270

Test Case 1: Corner and center points
  (   0,    0) -> (   0.00, 270.00) ‚úÖ
  ( 800,  320) -> (1640.00, 590.00) ‚úÖ
  ( 400,  160) -> ( 820.00, 430.00) ‚úÖ

Test Case 2: Output range validation
  X coordinates in range [0, 1640]: ‚úÖ
  Y coordinates in range [270, 590]: ‚úÖ

Test Case 3: Verify scaling factors
  X scale factor: 2.050000 ‚úÖ
  Y scale factor: 1.000000 ‚úÖ
  Y offset: 270 pixels ‚úÖ

üéâ All tests PASSED!
```

### Expected Behavior After Fix

| Point Location | Resized Space (800√ó320) | Original Space (1640√ó590) |
|----------------|-------------------------|---------------------------|
| Top-left       | (0, 0)                  | (0, 270)                  |
| Top-right      | (800, 0)                | (1640, 270)               |
| Bottom-left    | (0, 320)                | (0, 590)                  |
| Bottom-right   | (800, 320)              | (1640, 590)               |
| Center         | (400, 160)              | (820, 430)                |

## Impact

### Before Fix
- ‚ùå Evaluation metrics incorrectly calculated
- ‚ùå Lane coordinates compressed and misaligned
- ‚ùå Missing vertical offset (270 pixels)
- ‚ùå Impossible to achieve accurate F1 scores

### After Fix
- ‚úÖ Coordinates properly mapped to original image space
- ‚úÖ Evaluation metrics correctly calculated
- ‚úÖ Proper vertical offset applied
- ‚úÖ Accurate lane detection evaluation possible

## Files Modified

1. **test_afplnet_inference.py** (lines 208-215)
   - Added coordinate mapping transformation
   - Preserves backward compatibility with hasattr checks

## Verification Steps

To verify the fix is working:

1. **Check coordinate ranges in output files**:
   ```bash
   # Output coordinates should be in [0, 1640] √ó [270, 590] range
   head result/driver_*.lines.txt
   ```

2. **Compare evaluation metrics**:
   - F1 scores should improve significantly after fix
   - Precision and recall should be more accurate

3. **Visual inspection**:
   ```bash
   python test_afplnet_inference.py --is_view 1
   # Check that visualizations align with ground truth
   ```

## Related Files

- **Config**: `Config/afplnet_culane_r18.py` (defines image dimensions)
- **Network**: `Models/Head/afpl_head.py` (post_process function)
- **Inference**: `test_afplnet_inference.py` (format_afplnet_output function)
- **Evaluation**: `Eval/utils/eval_utils.py` (write_output_culane_format function)
- **Evaluator**: `Eval/culane_evaluator.py` (write_output method)

## Testing Checklist

- [x] Unit test validates coordinate mapping formula
- [x] Python syntax check passes
- [x] CodeQL security scan passes (0 alerts)
- [x] Changes are minimal and surgical
- [x] Backward compatibility maintained
- [ ] Full integration test with model weights (requires torch installation)
- [ ] Evaluation metrics comparison before/after fix

## Notes

- The fix is **backward compatible**: uses `hasattr()` checks to ensure config has required attributes
- The fix is **minimal**: only 8 lines of code added in one location
- The fix is **correct**: validated with comprehensive unit tests
- The fix **doesn't break existing behavior**: only transforms coordinates when all required config values are present

## Author

Fixed by: GitHub Copilot  
Date: 2025-11-18  
Issue: Coordinate mapping from resized to original image space
